{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import sys; sys.path.insert(0, '..') # if you don't find it here, look one above\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as spio\n",
    "import pickle\n",
    "# stored one repo up in my fork of Spykes\n",
    "from spykes.spykes.plot.neurovis import NeuroVis\n",
    "from io_utils import *\n",
    "from plotting_utils import * \n",
    "\n",
    "# settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "timely-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brodylab\\Documents\\GitHub\\jbreda_PWM_ephys_analysis\\io_utils.py:249: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  beh_df['hit_hist'][beh_df['hit_hist'].isnull()] = \"viol\"\n"
     ]
    }
   ],
   "source": [
    "# base paths/names\n",
    "sess_names = np.load('sess_names.npy')\n",
    "sess_name = sess_names[4]\n",
    "\n",
    "base_path  = 'Y:\\jbreda\\ephys\\post_sort_analysis\\sorted_pre_bdata' \n",
    "beh_mat   = 'protocol_info.mat'\n",
    "spks_mat  = 'ksphy_clusters_foranalysis.mat'\n",
    "\n",
    "\n",
    "# create paths\n",
    "sess_path = os.path.join(base_path, sess_name)\n",
    "beh_path  = os.path.join(sess_path, beh_mat)\n",
    "spks_path = os.path.join(sess_path, spks_mat)\n",
    "fig_save_path = os.path.join(os.getcwd(), 'figures', 'neurovis', sess_name)\n",
    "\n",
    "# load & wrangle\n",
    "beh_df, spks_dict = load_and_wrangle(beh_path, spks_path, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "demanding-windows",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing mask_dict...\n",
      "Done loading.\n",
      "ngood, first: 14\n",
      "ngood, first: 14\n",
      "ngood, second: 16\n",
      "ngood, second: 16\n",
      "ngood, second: 16\n",
      "ngood, second: 16\n"
     ]
    }
   ],
   "source": [
    "# filter dataframe\n",
    "beh_df_d2_h = beh_df[(beh_df['delay'] == 2)\n",
    "       & (beh_df['hit_hist'] == 'hit')]\n",
    "\n",
    "# deal with masking\n",
    "bndl_dfs, df_names = deal_with_masking(spks_dict, beh_df_d2_h, sess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "destroyed-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilaize\n",
    "events = ['aud1_on']\n",
    "windows = [[-1000,2300]]\n",
    "condition = 'correct_side'\n",
    "\n",
    "# get neurons into NeuroVis objects\n",
    "neurons = initiate_neurons(spks_dict)\n",
    "neuron = NeuroVis(spks_dict['spk_times'][0])\n",
    "\n",
    "#single neuron debug\n",
    "window = windows[0]\n",
    "binsize = 100\n",
    "df = bndl_dfs[df_names[0]]\n",
    "phys_start = neuron.spiketimes[0]\n",
    "phys_end = neuron.spiketimes[-1]\n",
    "event = events[0]\n",
    "conditions = 'correct_side'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "possible-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_rasters = get_neuron_rasters(neurons, events, windows, bndl_dfs, df_names)\n",
    "neuron_psths = get_neuron_psths(neurons, events, windows, bndl_dfs, df_names, conditions=condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "blank-jersey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 17)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not type(df) is dict:\n",
    "        df = df.reset_index()\n",
    "len(np.sum(raster['data'][0], axis = 1)), len(psth['data'][0]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "gentle-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not type(df) is dict:\n",
    "    df2 = df.reset_index()\n",
    "wind = [np.floor(window[0]/binsize) * binsize, np.ceil(window[1]/binsize) * binsize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "complimentary-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = dict()\n",
    "trials[0] = np.where(np.ones(np.size(df[event])))[0]\n",
    "rasters = {\n",
    "        'event': event,\n",
    "        'conditions': conditions,\n",
    "        'window': window,\n",
    "        'binsize': binsize,\n",
    "        'data': {},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "loved-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond_id in trials:\n",
    "    # Select events relevant to this raster\n",
    "    selected_events = df[event].iloc[trials[cond_id]]\n",
    "\n",
    "    raster = []\n",
    "    \n",
    "    bin_template = 1e-3 * np.arange(window[0], window[1] + binsize, binsize)\n",
    "    \n",
    "    for event_time in selected_events:\n",
    "        bins = event_time + bin_template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "assigned-investigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1. , -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1,  0. ,\n",
       "        0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,  1.1,\n",
       "        1.2,  1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9,  2. ,  2.1,  2.2,\n",
       "        2.3])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "transsexual-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5867.858354 5867.958354 5868.058354 5868.158354 5868.258354 5868.358354\n",
      " 5868.458354 5868.558354 5868.658354 5868.758354 5868.858354 5868.958354\n",
      " 5869.058354 5869.158354 5869.258354 5869.358354 5869.458354 5869.558354\n",
      " 5869.658354 5869.758354 5869.858354 5869.958354 5870.058354 5870.158354\n",
      " 5870.258354 5870.358354 5870.458354 5870.558354 5870.658354 5870.758354\n",
      " 5870.858354 5870.958354 5871.058354 5871.158354]\n"
     ]
    }
   ],
   "source": [
    "for event_time in selected_events:\n",
    "    bins = event_time + bin_template\n",
    "    \n",
    "    searchsorted_idx = np.sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "appointed-street",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5868.858354, 5867.858354, 5871.158354)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_time, event_time + 1e-3 * window[0], event_time + 1e-3 * window[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-strength",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
