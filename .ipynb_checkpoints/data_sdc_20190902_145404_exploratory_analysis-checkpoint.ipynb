{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "renewable-income",
   "metadata": {},
   "source": [
    "# Explortatory analysis \n",
    "\n",
    "Notebook for exploratory analysis on tetrode data in the mPFC of a rat doing the parametric working memory (PWM) task.\n",
    "\n",
    "Session: `data_sdc_20190902_145404_fromSD`\n",
    "\n",
    "Current data storage:\n",
    "* raw .dat, .rec, .mda, .bin and preprocessed .bin files are located on scratch under ``\n",
    "\n",
    "* sorted data is located on bucket `Y:\\jbreda\\ephys\\post_sort_analysis\\sorted_pre_bdata`\n",
    "\n",
    "* in a sorted folder: \n",
    "    * folder for each .bin bundle & cluster notes, matlab struct w/ spike info from scraped phy, matlab struct w/ behavior info scraped from bdata\n",
    "    * in .bin bundle folder you will find curated kilosort output, mask info as npy and preprocessed .bin that was run\n",
    "\n",
    "see [jbreda_PWM_ephys_analysis](https://github.com/Brody-Lab/jbreda_PWM_ephys_analysis) for more info on how this info was obtained\n",
    "\n",
    "\n",
    "**TODO**\n",
    "* spk struct --> data frame\n",
    "* make utils.py\n",
    "* turn df cell into function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-combination",
   "metadata": {},
   "source": [
    "## Libs & fxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brief-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "victorian-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nested_mat(filename):\n",
    "    \"\"\"\n",
    "    This function should be called instead of direct scipy.io.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects. From https://stackoverflow.com/questions\n",
    "    /48970785/complex-matlab-struct-mat-file-read-by-python\n",
    "    \"\"\"\n",
    "\n",
    "    def _check_vars(d):\n",
    "        \"\"\"\n",
    "        Checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        \"\"\"\n",
    "        for key in d:\n",
    "            if isinstance(d[key], matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "            elif isinstance(d[key], np.ndarray):\n",
    "                d[key] = _toarray(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        \"\"\"\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        \"\"\"\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _toarray(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _toarray(ndarray):\n",
    "        \"\"\"\n",
    "        A recursive function which constructs ndarray from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        \"\"\"\n",
    "        if ndarray.dtype != 'float64':\n",
    "            elem_list = []\n",
    "            for sub_elem in ndarray:\n",
    "                if isinstance(sub_elem, matlab.mio5_params.mat_struct):\n",
    "                    elem_list.append(_todict(sub_elem))\n",
    "                elif isinstance(sub_elem, np.ndarray):\n",
    "                    elem_list.append(_toarray(sub_elem))\n",
    "                else:\n",
    "                    elem_list.append(sub_elem)\n",
    "            return np.array(elem_list)\n",
    "        else:\n",
    "            return ndarray\n",
    "\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_vars(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-spell",
   "metadata": {},
   "source": [
    "## Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "timely-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_path = 'Y:\\jbreda\\ephys\\post_sort_analysis\\sorted_pre_bdata\\data_sdc_20190902_145404_fromSD\\protocol_info.mat'\n",
    "beh_dict = load_nested_mat(beh_path)\n",
    "beh_dict = beh_dict['behS']\n",
    "parsed_events_dict = beh_dict['parsed_events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "growing-matrix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_hist</th>\n",
       "      <th>delay</th>\n",
       "      <th>pair_hist</th>\n",
       "      <th>correct_side</th>\n",
       "      <th>prev_side</th>\n",
       "      <th>aud1_sigma</th>\n",
       "      <th>aud2_sigma</th>\n",
       "      <th>c_poke</th>\n",
       "      <th>hit_state</th>\n",
       "      <th>aud1_time</th>\n",
       "      <th>aud2_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>476.563229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0.053144</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>479.869221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>482.048223</td>\n",
       "      <td>490.309221</td>\n",
       "      <td>482.098232</td>\n",
       "      <td>488.499224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>498.909227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>505.471227</td>\n",
       "      <td>509.341221</td>\n",
       "      <td>505.522228</td>\n",
       "      <td>507.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>5227.210220</td>\n",
       "      <td>5231.212228</td>\n",
       "      <td>5227.260225</td>\n",
       "      <td>5229.661221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>5241.322233</td>\n",
       "      <td>5245.159224</td>\n",
       "      <td>5241.373230</td>\n",
       "      <td>5243.773224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>5251.930228</td>\n",
       "      <td>5255.634227</td>\n",
       "      <td>5251.980234</td>\n",
       "      <td>5254.381225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>5261.118223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>5274.193220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hit_hist  delay  pair_hist correct_side prev_side  aud1_sigma  \\\n",
       "0         NaN      6          9        RIGHT       NaN    0.008904   \n",
       "1         NaN      4          4        RIGHT     RIGHT    0.053144   \n",
       "2         1.0      6          3        RIGHT     RIGHT    0.019683   \n",
       "3         0.0      2          9        RIGHT     RIGHT    0.008904   \n",
       "4         1.0      2          6         LEFT     RIGHT    0.002700   \n",
       "..        ...    ...        ...          ...       ...         ...   \n",
       "400       1.0      2          2        RIGHT      LEFT    0.007290   \n",
       "401       1.0      2         12         LEFT     RIGHT    0.002704   \n",
       "402       1.0      2         14         LEFT      LEFT    0.005985   \n",
       "403       NaN      6          7         LEFT      LEFT    0.007290   \n",
       "404       NaN      2          5         LEFT      LEFT    0.001000   \n",
       "\n",
       "     aud2_sigma       c_poke    hit_state    aud1_time    aud2_time  \n",
       "0      0.007300   476.563229          NaN          NaN          NaN  \n",
       "1      0.019683   479.869221          NaN          NaN          NaN  \n",
       "2      0.007290   482.048223   490.309221   482.098232   488.499224  \n",
       "3      0.007300   498.909227          NaN          NaN          NaN  \n",
       "4      0.007290   505.471227   509.341221   505.522228   507.922222  \n",
       "..          ...          ...          ...          ...          ...  \n",
       "400    0.002700  5227.210220  5231.212228  5227.260225  5229.661221  \n",
       "401    0.007300  5241.322233  5245.159224  5241.373230  5243.773224  \n",
       "402    0.007300  5251.930228  5255.634227  5251.980234  5254.381225  \n",
       "403    0.019683  5261.118223          NaN          NaN          NaN  \n",
       "404    0.002700  5274.193220          NaN          NaN          NaN  \n",
       "\n",
       "[405 rows x 11 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize df\n",
    "beh_df = pd.DataFrame()\n",
    "\n",
    "# make any adjustments\n",
    "prev_side_adj = np.roll(beh_dict['prev_side'],1) # n-1 trial info\n",
    "prev_side_adj = np.where(prev_side_adj == 114, 'RIGHT', 'LEFT' )\n",
    "prev_side_adj[0] = 'NaN' # trial 0 doesn't have a previous\n",
    "\n",
    "# get n_trial length items into df\n",
    "beh_df['hit_hist'] = beh_dict['hit_history']\n",
    "beh_df['delay'] = beh_dict['delay']\n",
    "beh_df['pair_hist'] = beh_dict['pair_history']\n",
    "beh_df['correct_side'] = beh_dict['correct_side']\n",
    "beh_df['prev_side'] = prev_side_adj\n",
    "beh_df['aud1_sigma'] = beh_dict['aud1_sigma']\n",
    "beh_df['aud2_sigma'] = beh_dict['aud2_sigma']\n",
    " \n",
    "# initilize space    \n",
    "c_poke = np.zeros((len(parsed_events_dict)))\n",
    "hit_state = np.zeros((len(parsed_events_dict)))\n",
    "aud1_time = np.zeros((len(parsed_events_dict)))\n",
    "aud2_time = np.zeros((len(parsed_events_dict)))\n",
    "\n",
    "# iterate over items from state matrix\n",
    "for trial in range(len(parsed_events_dict)):\n",
    "    \n",
    "    # every trial has a center poke\n",
    "    c_poke[trial] = parsed_events_dict[trial]['states']['cp'][0]\n",
    "    \n",
    "    # not all trials will have sound/hit time/etc, pull out info for hits\n",
    "    if beh_df['hit_hist'][trial] == 1.0:\n",
    "        \n",
    "        hit_state[trial] = parsed_events_dict[trial]['states']['hit_state'][0]\n",
    "        aud1_time[trial] = parsed_events_dict[trial]['waves']['stimAUD1'][0]\n",
    "        aud2_time[trial] = parsed_events_dict[trial]['waves']['stimAUD2'][0]\n",
    "    else:\n",
    "        hit_state[trial] = float(\"NaN\")\n",
    "        aud1_time[trial] = float(\"NaN\")\n",
    "        aud2_time[trial] = float(\"NaN\")\n",
    "\n",
    "# add to df\n",
    "beh_df['c_poke'] = c_poke\n",
    "beh_df['hit_state'] = hit_state\n",
    "beh_df['aud1_time'] = aud1_time\n",
    "beh_df['aud2_time'] = aud2_time\n",
    " \n",
    "beh_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-hamilton",
   "metadata": {},
   "source": [
    "## Ephys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "traditional-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "spks_path = 'Y:\\jbreda\\ephys\\post_sort_analysis\\sorted_pre_bdata\\data_sdc_20190902_145404_fromSD\\ksphy_clusters_foranalysis.mat'\n",
    "spks_dict = spio.loadmat(spks_path, squeeze_me = True)\n",
    "spks_dict = spks_dict['PWMspkS']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
